#!/usr/bin/env python
"""
NoiseChain CLI ë°ëª¨

E2E íŒŒì´í”„ë¼ì¸ì„ ì‹œì—°í•˜ëŠ” ì»¤ë§¨ë“œë¼ì¸ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python -m noisechain.demo generate      # í† í° ìƒì„±
    python -m noisechain.demo verify <hash> # í† í° ê²€ì¦
    python -m noisechain.demo stats         # í†µê³„ ì¡°íšŒ
    python -m noisechain.demo benchmark     # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
"""

import argparse
import json
import sys
import time
from pathlib import Path

import numpy as np

from noisechain import NoiseChainPipeline, PipelineConfig, create_pipeline


def print_banner():
    """ë°°ë„ˆ ì¶œë ¥"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     NoiseChain MVP                        â•‘
â•‘           Physical Trust Verification Network             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)


def cmd_generate(args):
    """í† í° ìƒì„± ëª…ë ¹"""
    print("\nğŸ“¡ ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    
    config = PipelineConfig(
        db_path=args.db if args.db else ":memory:",
        sample_count=args.samples
    )
    
    with NoiseChainPipeline(config) as pipeline:
        # í† í° ìƒì„±
        start = time.perf_counter()
        result = pipeline.generate_and_store()
        elapsed = time.perf_counter() - start
        
        if result.success:
            token = result.token
            report = result.verification
            
            print(f"\nâœ… í† í° ìƒì„± ì„±ê³µ! ({elapsed*1000:.1f}ms)")
            print(f"\nğŸ“‹ í† í° ì •ë³´:")
            print(f"   í•´ì‹œ: {token.compute_hash().hex()[:32]}...")
            print(f"   ë…¸ë“œ ID: {token.node_id_hex[:16]}...")
            print(f"   ìœ„í—˜ ì ìˆ˜: {token.risk_score:.2f}")
            print(f"   í¬ê¸°: {token.size} bytes")
            print(f"   ì„œëª…ë¨: {'ì˜ˆ' if token.is_signed else 'ì•„ë‹ˆì˜¤'}")
            
            print(f"\nğŸ” ê²€ì¦ ê²°ê³¼:")
            print(f"   ìœ íš¨: {'âœ… ì˜ˆ' if report.is_valid else 'âŒ ì•„ë‹ˆì˜¤'}")
            print(f"   í†µê³¼: {report.passed_count}ê°œ")
            print(f"   ì‹¤íŒ¨: {report.failed_count}ê°œ")
            
            for step in report.steps:
                icon = "âœ…" if step.passed else "âŒ"
                print(f"   {icon} {step.name}: {step.message}")
        else:
            print(f"\nâŒ í† í° ìƒì„± ì‹¤íŒ¨: {result.error}")
            return 1
    
    return 0


def cmd_verify(args):
    """í† í° ê²€ì¦ ëª…ë ¹"""
    print(f"\nğŸ” í† í° ê²€ì¦ ì¤‘: {args.hash[:32]}...")
    
    try:
        token_hash = bytes.fromhex(args.hash)
    except ValueError:
        print("âŒ ì˜ëª»ëœ í•´ì‹œ í˜•ì‹ì…ë‹ˆë‹¤.")
        return 1
    
    config = PipelineConfig(db_path=args.db if args.db else ":memory:")
    
    with NoiseChainPipeline(config) as pipeline:
        report = pipeline.verify_by_hash(token_hash)
        
        if report is None:
            print("âŒ í† í°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 1
        
        print(f"\nğŸ“‹ ê²€ì¦ ê²°ê³¼:")
        print(f"   ìœ íš¨: {'âœ… ì˜ˆ' if report.is_valid else 'âŒ ì•„ë‹ˆì˜¤'}")
        
        for step in report.steps:
            icon = "âœ…" if step.passed else "âŒ"
            print(f"   {icon} {step.name}: {step.message}")
    
    return 0


def cmd_stats(args):
    """í†µê³„ ì¡°íšŒ ëª…ë ¹"""
    print("\nğŸ“Š ì €ì¥ì†Œ í†µê³„ ì¡°íšŒ ì¤‘...")
    
    config = PipelineConfig(db_path=args.db if args.db else ":memory:")
    
    with NoiseChainPipeline(config) as pipeline:
        stats = pipeline.get_stats()
        
        print(f"\nğŸ“‹ í†µê³„:")
        print(f"   ë…¸ë“œ ID: {stats['node_id'][:16]}...")
        print(f"   ì´ í† í° ìˆ˜: {stats['total_tokens']}")
        print(f"   ì´ í¬ê¸°: {stats['total_size_bytes']:,} bytes")
        print(f"   ê³ ìœ  ë…¸ë“œ ìˆ˜: {stats['unique_nodes']}")
    
    return 0


def cmd_benchmark(args):
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ëª…ë ¹"""
    print("\nâš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...")
    print(f"   ë°˜ë³µ íšŸìˆ˜: {args.iterations}")
    print(f"   ìƒ˜í”Œ ìˆ˜: {args.samples}")
    
    config = PipelineConfig(sample_count=args.samples)
    
    times = []
    with NoiseChainPipeline(config) as pipeline:
        for i in range(args.iterations):
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
            sensor_data = {
                "cpu_temp": 50 + 10 * np.sin(np.linspace(0, 2*np.pi, args.samples)),
                "entropy": np.random.randint(0, 256, args.samples).astype(float),
                "jitter": np.random.randn(args.samples) * 100,
            }
            
            start = time.perf_counter()
            result = pipeline.generate_and_store(sensor_data)
            elapsed = time.perf_counter() - start
            
            times.append(elapsed)
            
            if not result.success:
                print(f"âŒ ë°˜ë³µ {i+1} ì‹¤íŒ¨")
                return 1
            
            print(f"   [{i+1}/{args.iterations}] {elapsed*1000:.1f}ms", end="\r")
    
    print("\n")
    
    # í†µê³„ ê³„ì‚°
    times_ms = [t * 1000 for t in times]
    avg = np.mean(times_ms)
    std = np.std(times_ms)
    min_t = np.min(times_ms)
    max_t = np.max(times_ms)
    throughput = 1000/avg if avg > 0 else 0
    
    # ê²°ê³¼ ìš”ì•½
    results = {
        "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S"),
        "config": {"iterations": args.iterations, "samples": args.samples},
        "stats": {
            "mean_ms": float(avg),
            "std_ms": float(std),
            "min_ms": float(min_t),
            "max_ms": float(max_t),
            "throughput_tps": float(throughput)
        }
    }
    
    print(f"ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
    print(f"   í‰ê· : {avg:.2f}ms")
    print(f"   í‘œì¤€í¸ì°¨: {std:.2f}ms")
    print(f"   ìµœì†Œ: {min_t:.2f}ms")
    print(f"   ìµœëŒ€: {max_t:.2f}ms")
    print(f"   ì²˜ë¦¬ëŸ‰: {throughput:.1f} tokens/sec")
    
    # íŒŒì¼ ì €ì¥
    if args.output:
        import json
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {args.output}")
        
    return 0


def cmd_demo(args):
    """ì „ì²´ ë°ëª¨ ëª…ë ¹"""
    print_banner()
    
    print("ğŸ¬ NoiseChain E2E ë°ëª¨ ì‹œì‘\n")
    
    with create_pipeline() as pipeline:
        # 1. ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘
        print("1ï¸âƒ£  ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘...")
        sensor_data = {
            "cpu_temp": 50 + 10 * np.sin(np.linspace(0, 4*np.pi, 256)),
            "os_entropy": np.random.randint(0, 256, 256).astype(float),
            "clock_jitter": np.random.randn(256) * 100,
            "synthetic": np.random.randn(256) * 0.5,
        }
        print(f"   âœ… 4ê°œ ì„¼ì„œ, 256 ìƒ˜í”Œ ìˆ˜ì§‘ ì™„ë£Œ\n")
        
        # 2. í† í° ìƒì„± ë° ì„œëª…
        print("2ï¸âƒ£  PoXToken ìƒì„± ì¤‘...")
        start = time.perf_counter()
        result = pipeline.generate_and_store(sensor_data)
        elapsed = time.perf_counter() - start
        
        token = result.token
        print(f"   âœ… í† í° ìƒì„± ì™„ë£Œ ({elapsed*1000:.1f}ms)")
        print(f"   ğŸ“¦ í¬ê¸°: {token.size} bytes")
        print(f"   ğŸ” ì„œëª…: {token.signature.hex()[:32]}...\n")
        
        # 3. ê²€ì¦
        print("3ï¸âƒ£  í† í° ê²€ì¦ ì¤‘...")
        report = result.verification
        print(f"   âœ… ê²€ì¦ ì™„ë£Œ")
        print(f"   ğŸ“‹ ê²°ê³¼: {'ìœ íš¨' if report.is_valid else 'ë¬´íš¨'}")
        for step in report.steps:
            icon = "âœ…" if step.passed else "âŒ"
            print(f"      {icon} {step.name}: {step.message}\n")
        
        # 4. ì €ì¥ì†Œ í†µê³„
        print("4ï¸âƒ£  ì €ì¥ì†Œ í†µê³„:")
        stats = pipeline.get_stats()
        print(f"   ğŸ“Š ì´ í† í°: {stats['total_tokens']}")
        print(f"   ğŸ’¾ ì´ í¬ê¸°: {stats['total_size_bytes']} bytes\n")
        
        print("ğŸ‰ ë°ëª¨ ì™„ë£Œ!")
    
    return 0


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="NoiseChain CLI - Physical Trust Verification Network"
    )
    parser.add_argument(
        "--db", 
        help="SQLite ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ (ê¸°ë³¸: ì¸ë©”ëª¨ë¦¬)"
    )
    
    subparsers = parser.add_subparsers(dest="command", help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹")
    
    # generate ëª…ë ¹
    gen_parser = subparsers.add_parser("generate", help="í† í° ìƒì„±")
    gen_parser.add_argument(
        "--samples", 
        type=int, 
        default=256, 
        help="ìˆ˜ì§‘í•  ìƒ˜í”Œ ìˆ˜"
    )
    
    # verify ëª…ë ¹
    verify_parser = subparsers.add_parser("verify", help="í† í° ê²€ì¦")
    verify_parser.add_argument("hash", help="ê²€ì¦í•  í† í° í•´ì‹œ (16ì§„ìˆ˜)")
    
    # stats ëª…ë ¹
    subparsers.add_parser("stats", help="ì €ì¥ì†Œ í†µê³„")
    
    # benchmark ëª…ë ¹
    bench_parser = subparsers.add_parser("benchmark", help="ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    bench_parser.add_argument(
        "--iterations", 
        type=int, 
        default=10, 
        help="ë°˜ë³µ íšŸìˆ˜"
    )
    bench_parser.add_argument(
        "--samples", 
        type=int, 
        default=256, 
        help="ìƒ˜í”Œ ìˆ˜"
    )
    bench_parser.add_argument(
        "--output", 
        help="ê²°ê³¼ ì €ì¥ íŒŒì¼ ê²½ë¡œ (JSON)"
    )
    
    # demo ëª…ë ¹
    subparsers.add_parser("demo", help="ì „ì²´ ë°ëª¨ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    if args.command == "generate":
        return cmd_generate(args)
    elif args.command == "verify":
        return cmd_verify(args)
    elif args.command == "stats":
        return cmd_stats(args)
    elif args.command == "benchmark":
        return cmd_benchmark(args)
    elif args.command == "demo":
        return cmd_demo(args)
    else:
        print_banner()
        parser.print_help()
        return 0


if __name__ == "__main__":
    sys.exit(main())
